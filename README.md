# Pipeline ETL com Python: Validando Dados e Planilhas de Excel para um Dashboard

Este projeto visa criar um pipeline ETL utilizando Python, focando na valida√ß√£o de dados e na transforma√ß√£o de planilhas de Excel em um dashboard interativo e informativo. O objetivo √© acompanhar o desempenho durante as minhas tarefas de atendimento na empresa, garantindo a qualidade e integridade dos dados antes de serem visualizados.

## Funcionalidades do Projeto

### 1. **Profile Report do Pandas Profiling**
A primeira etapa do pipeline consiste em gerar um **relat√≥rio de perfil** (Profile Report) utilizando a biblioteca **Pandas Profiling**. Esse relat√≥rio fornece uma an√°lise explorat√≥riado dataset, destacando a distribui√ß√£o dos dados, valores ausentes, correla√ß√µes, e outros insights valiosos para entender a qualidade do dataset.

- **Arquivo:** `main.py`
- **Print da funcionalidade:**
  ![An√°lise Explorat√≥ria](images/pandas-profiling-ok.png)



### 2. **Contrato de Dados**
Em seguida, utilizamos um **contrato de dados** para garantir que os dados preenchidos estejam dentro de um padr√£o espec√≠fico. Este contrato √© configurado em um arquivo separado para ser utilizado como refer√™ncia durante a valida√ß√£o dos dados.

- **Arquivo:** `validador_dados.py`



### 3. **Valida√ß√£o do Dataset**
A terceira etapa do pipeline envolve a **valida√ß√£o** do dataset. Ap√≥s preencher o arquivo `.csv`, a aplica√ß√£o ir√° verificar se os dados est√£o dentro das condi√ß√µes aceitas no contrato de dados. Caso um erro seja encontrado, ele ser√° identificado, juntamente com a linha do erro e sugest√µes de onde procurar a solu√ß√£o.

- **Arquivo:** `aplicacao.py`
- **Print da funcionalidade:**
  ![Validando dados pegando os erros](images/validador-nok.png)

  *Na imagem acima, o validador identificou erros nos dados, como campos fora do contrato, tipos incorretos ou valores inv√°lidos. A linha e o tipo do erro s√£o mostrados para facilitar a corre√ß√£o.*

  ![Validando dados com tudo corrigido](images/validador-ok.png)

  *Ap√≥s as corre√ß√µes, os dados s√£o validados com sucesso, sem erros detectados. Isso garante que o dataset est√° pronto para ser usado no dashboard.*



### 4. **Dashboard de Visualiza√ß√£o**
Ap√≥s corrigir os erros e garantir que os dados est√£o de acordo com o contrato, o √∫ltimo passo do pipeline √© enviar os dados para um **dashboard**. O dashboard √© projetado para fornecer uma visualiza√ß√£o simples, mas fiel ao objetivo de acompanhamento de desempenho. Ele exibe m√©tricas e gr√°ficos baseados no dataset validado.

- **Arquivo:** `dashboard.py`
- **Print da funcionalidade:**
  ![Validando dados com tudo corrigido](images/dashboard.png)



## Como Executar

Para rodar este projeto localmente, siga os seguintes passos:

### 1. Clone este reposit√≥rio:
```bash
git clone https://github.com/seu-usuario/pipeline-etl-dashboard.git
cd pipeline-etl-dashboard
```

### 2. Instale as desped√™ncias:
``` bash
pip install -r requirements.txt
```

### 3. Execute o script main.py para gerar o profile report:
``` bash
python main.py
```

### 4. Defina as regras de valida√ß√£o no arquivo validador_dados.py.
Cada contrato de dados precisa de um validador, ent√£o √© necess√°rio a defini√ß√£o do validador.

### 5. Execute o script aplicacao.py para validar o dataset:
``` bash
streamlit run src/aplicacao.py
```

### 6. Visualize o dashboard com os dados validados.
O dashboard pode variar conforme as necessidades do usu√°rio, desde que ele fa√ßa essas altera√ß√µes no:
```bash
streamlit run src/aplicacao.py
```

## Contato

üîó[Conecte-se comigo no LinkedIn](https://www.linkedin.com/in/marianapacini-dataengineer/)